{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [02:32<00:00, 76.42s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>[So I think we would not be alive if our ances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>[Not for use with a car . , Do not use in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>[Here was no promise of morning , except that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>[Thus , even today , sex is considered as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[Imagine yourself you are working in factory j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "      <td>[The government should also try to reduce the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "      <td>[A lot of memories , with enough time to remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Sceene of violence can affect on them .</td>\n",
       "      <td>[A scene of violence can have an effect on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>[The communities in general have reckoned that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td></td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1                                   For not use car .    \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus even today sex is considered as the least...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government also should try to reduce the s...   \n",
       "751  Alot of memories with enogh time to remember w...   \n",
       "752           Sceene of violence can affect on them .    \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                           corrections  \n",
       "0    [So I think we would not be alive if our ances...  \n",
       "1    [Not for use with a car . , Do not use in the ...  \n",
       "2    [Here was no promise of morning , except that ...  \n",
       "3    [Thus , even today , sex is considered as the ...  \n",
       "4    [Imagine yourself you are working in factory j...  \n",
       "..                                                 ...  \n",
       "750  [The government should also try to reduce the ...  \n",
       "751  [A lot of memories , with enough time to remem...  \n",
       "752  [A scene of violence can have an effect on the...  \n",
       "753  [The communities in general have reckoned that...  \n",
       "754                                           [, , , ]  \n",
       "\n",
       "[755 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = {'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/jhu-clsp/jfleg/\" + splits[\"validation\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So I think we can not live if old people could not find siences and tecnologies and they did not developped . ',\n",
       " 'For not use car . ',\n",
       " 'Here was no promise of morning except that we looked up through the trees we saw how low the forest had swung . ',\n",
       " 'Thus even today sex is considered as the least important topic in many parts of India . ',\n",
       " 'image you salf you are wark in factory just to do one thing like pot taire on car if they fire you you will destroy , becouse u dont know more than pot taire in car . ',\n",
       " 'They draw the consumers , like me , to purchase this great product with all these amazing ingredients and all that but actually they just sometimes make something up just to increase their sales . ',\n",
       " 'I want to talk about nocive or bad products like alcohol , hair spray and cigarrets . ',\n",
       " 'For example they can play football whenever they want but the olders can not . ',\n",
       " 'It figures Diana Krall wearing a Rolex watch and has a text that suggests that if the reader wants to belong to the restricted club , not necessarily of Rolex watch wearers , but of highly talented , sophisticated and competent artists , he or she should also have a Rolex . ',\n",
       " 'There are several reason . ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df[\"sentence\"].tolist()[:10]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_sentences = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "tokenized_sentences = {k: v.to(device) for k, v in tokenized_sentences.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(\n",
    "        **tokenized_sentences, \n",
    "        max_length=4,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 56, 2048])\n",
      "torch.Size([10, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(output.hidden_states[-1].shape)\n",
    "\n",
    "# get the hidden states for the last layer\n",
    "last_hidden_states = output.hidden_states[-1]\n",
    "print(last_hidden_states[:, -1, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 1.7227,  4.1797,  0.4827,  ..., -3.5352, -4.4727, -0.0364],\n",
      "         [ 2.9551,  3.5996,  0.8955,  ...,  0.5044, -5.7305, -0.7026],\n",
      "         ...,\n",
      "         [-0.5122,  3.4785, -0.7607,  ..., -0.3057,  2.7070,  0.2009],\n",
      "         [-0.4985,  3.4707, -0.7036,  ..., -0.2144,  2.6152,  0.3516],\n",
      "         [-0.5576,  3.4648, -0.6382,  ..., -0.0870,  2.5430,  0.4092]],\n",
      "\n",
      "        [[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 0.9595,  2.0977,  2.1934,  ..., -5.8633, -5.9609,  0.2430],\n",
      "         [ 0.8931,  3.8398,  1.7012,  ..., -3.0137, -5.3867, -1.1514],\n",
      "         ...,\n",
      "         [-0.5483,  3.4922,  1.5713,  ...,  0.7861,  0.5498,  0.2510],\n",
      "         [-0.4812,  3.4629,  1.6123,  ...,  0.8403,  0.5264,  0.3218],\n",
      "         [-0.4551,  3.5176,  1.6816,  ...,  0.9189,  0.4802,  0.2788]],\n",
      "\n",
      "        [[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 0.8232,  3.6406,  2.4062,  ..., -5.0664, -4.9062, -0.5850],\n",
      "         [ 1.9014,  4.3086,  1.7861,  ..., -5.7148, -4.5039,  1.0947],\n",
      "         ...,\n",
      "         [-0.4170,  3.1367, -0.2335,  ...,  0.3315,  2.6367,  0.4336],\n",
      "         [-0.5127,  3.1465, -0.1920,  ...,  0.4719,  2.5547,  0.4976],\n",
      "         [-0.6343,  3.1582, -0.0719,  ...,  0.6484,  2.4336,  0.5542]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 0.9595,  2.0977,  2.1934,  ..., -5.8633, -5.9609,  0.2430],\n",
      "         [ 1.3125,  3.8652,  3.7402,  ..., -5.4961, -5.2305, -0.0662],\n",
      "         ...,\n",
      "         [-0.3984,  3.4316,  0.0247,  ...,  0.8071,  2.0176,  0.7153],\n",
      "         [-0.3462,  3.4551,  0.0378,  ...,  0.8950,  1.9971,  0.6699],\n",
      "         [-0.3669,  3.4707,  0.1400,  ...,  1.1270,  2.0293,  0.7783]],\n",
      "\n",
      "        [[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 2.0781,  4.5430, -0.6274,  ..., -3.6426, -3.9102, -1.9688],\n",
      "         [-0.4644,  6.2227,  2.8887,  ..., -3.2461, -3.1973,  2.7441],\n",
      "         ...,\n",
      "         [-1.5322,  4.0586,  0.8774,  ..., -1.6201,  0.1816, -0.9746],\n",
      "         [ 1.4346,  4.2656,  1.4229,  ..., -5.2773, -1.6211,  2.4062],\n",
      "         [ 0.8462,  2.8965,  0.5005,  ..., -4.5508, -2.5195,  2.6094]],\n",
      "\n",
      "        [[ 1.5498, -1.5039,  2.7441,  ..., -0.6343,  0.6006, -1.0107],\n",
      "         [ 1.2178,  4.3398,  0.0829,  ..., -2.0234, -3.9805, -0.2805],\n",
      "         [ 0.7480,  5.1289,  2.0137,  ..., -5.7422, -6.8516, -1.7139],\n",
      "         ...,\n",
      "         [ 0.0852,  3.6953,  1.4453,  ...,  1.5117,  0.6274,  0.7656],\n",
      "         [ 0.1329,  3.7637,  1.4766,  ...,  1.5059,  0.6445,  0.8589],\n",
      "         [ 0.1238,  3.7812,  1.5342,  ...,  1.5195,  0.6187,  0.7979]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(output.hidden_states[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
